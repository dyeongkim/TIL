# 운영체제/OperatingSystem
## 2. 메모리 관리


### 2.1 메모리 계층 구조

#### 1. 레지스터
- CPU 자체 내에 위치한 가장 빠르고 작은 메모리 유형
- 명령을 실행하는 동안 데이터 및 중간 결과를 저장하는데 사용
- 레지스터의 수는 제한되어 있다.
- 용량은 B~KB 
#### 2. 캐시 메모리
자주 액세스하는 데이터를 저장하는 데 사용되는 작고 빠른 메모리   
CPU와 메인 메모리 사이의 버퍼 역할로 메모리 액세스 대기 시간을 줄인다.
- L1 캐시
    - CPU에 통합된 가장 빠르고 작은 캐시 수준

- L2 캐시
    - L1 캐시보다 느리고 크며 종종 CPU 코어 간에 공유

- L3 캐시
    - L2 캐시보다 느리고 크며 단일 프로세서의 모든 CPU코어 간에 공유

공간적 및 시간적 지역성, 캐시 교체 정책 ex) LRU(Least Recently Used Algorithm) 및 멀티 코어 시스템의 캐시 일관성 프로토콜과 같은 액세스 시간을 최적화하기 위해 다양한 전략 사용.

#### 3. 메인 메모리(RAM/Random Access Memory)
프로세스를 실행하고 임시 데이터를 저장하는데 사용되는 기본 저장공간.   
RAM은 휘발성으로 전원이 꺼지면 내용이 사라짐.

- DRAM(Dynamic RAM)
    - SRAM보다 느리다.
    - 데이터를 유지하기 위해 주기적으로 새로고침 필요

- SRAM(Static RAM)
    - DRAM보다 빠름.
    - 재생이 필요없지만 더 많은 전력을 소비.


#### 4. 보조 저장장치(디스크)
가장 느린 메모리 유형으로 장기 데이터 저장에 사용됨.   
비휘발성으로 시스템 전원이 꺼져도 내용이 저장됨.

- HDD(Hard Disk Drive)
    - 자기 디스크를 사용한 드라이브
    - 저렴한 대신 느림

- SSD(Solid-State Drive)
    - NAND 플래시 메모리를 사용하는 드라이브
    - 비싼 대신 더 빠른 액세스 시간과 높은 내구성

<br>

---

<br>


### 2.2 주소 공간
>프로세스가 실행 중에 액세스할 수 있는 메모리 주소의 범위   

#### 1. 코드(Code/Text) 세그먼트
- 프로세스의 실행 가능한 코드가 포함되는 부분
- 실행 중에 프로그램 코드가 실수 혹은 악의로 수정되지 않도록 읽기 전용(Read-only)
- 프로세스의 모든 인스턴스 간에 공유되ㅏ므로 전체 메모리 사용량이 줄어든다

#### 2. 데이터(Data) 세그먼트
- 프로세스에서 사용하는 전역 및 정적 변수가 포함되는 부분
- 두개의 하위 세그먼트로 나뉜다.
    - 초기화된 데이터 세그먼트
        - 명시적으로 초기화된 변수를 포함
        - 실행 파일에 저장되고 프로세스 생성 중에 메모리에 로드
    - 초기화 되지 않은 데이터 세그먼트 BSS(Block Stated Symbol)
        - 초기값 없는 전역변수, 배열, 정적(Static) 변수가 저장되는 영역
        - 프로세스가 실행될 때 자동으로 0으로 초기화

#### 3. 힙(Heap) 세그먼트
- 프로세스 실행 중 동적 메모리 할당에 사용된다.
- 메모리의 낮은 주소에서 높은 주소의 방향으로 할당
- 사용 가능한 메모리 블록을 찾고 조각화를 방지하는 메모리 관리자에 의해 관리됨

#### 4. 스택(Stack) 세그먼트
- 함수 매개 변수, 반환 주소 및 저장된 레지스스터 값과 같은 함수 호출 정보와 로컬 변수가 포함되는 부분
- 함수가 호출되고 반환될 때 자동으로 확장 및 축소 되는 **후입선출(LIFO)** 데이터 구조
- 함수 호출은 로컬 변수 및 관련 정보를 포함하는 새 스택 프레임을 생성
- Heap에서 생성된 Object 타입의 데이터 참조값이 할당됨.

<br>

스택 및 힙 세그먼트는 주소 공간의 반대쪽 끝에 배치되어 서로를 향해 확장된다.   
이 배열은 각 세그먼트의 사용 가능한 공간을 최대화하고 스택 오버플로 또는 힙 고갈의 위험을 최소화한다.

<br>

---

<br>

### 2.3 메모리 할당
컴퓨터 시스템에서 메모리를 예약하고 관리하는 프로세스.

#### 1. 정적 메모리 할당
> **컴파일 시간**에 변수 및 데이터 구조에 대한 메모리를 예약하는 프로세스   

메모리 주소와 크기는 고정되어 있으며 프로그램 실행중 변경되지 않는다.   
**전역 변수**, **static 변수** 및 **고정 크기 배열**에 사용
- 장점
    - 메모리 할당에 런타임 Overhaed가 없기 때문에 더 빠르고 효율적
    - 조각화와 같은 런타임 문제가 없으므로 메모리가 더 간단
- 단점
    - 메모리는 실행 중에 크기와 위치를 변경할 수 없으므로 유연하지 않다.
    - 비효율적인 메모리사용, 정적으로 할당된 메모리는 사용하지 않더라도 프로그램의 수명동안 예약됨.

#### 2. 동적 메모리 할당
> **런타임** 시 변수 및 데이터 구조에 대한 메모리를 예약하는 프로세스

메모리 주소와 크기가 프로그램 실행 중에 변경될 수 있으므로 보다 유연하고 효율적으로 메모리를 사용 가능

- 장점
    - 실행 중에 크기와 위치를 변경할 수 있으므로 메모리가 유연함
    - 필요에 따라 메모리를 할당 및 해제할 수 있으므로 효율적인 메모리 사용
- 단점
    - 메모리 할당에 런타임 Overhaed가 포함되므로 속도가 느리고 효율성이 떨어짐
    - 조각화와 같은 런타임 문제를 해결해야 하므로 메모리 관리가 복잡

*오버헤드(Overhaed)?*   
특정 기능을 수행하는데 드는 간접적인 시간, 메모리 등 자원   
ex) 프로그램 실행 도중 동떨어진 위치의 코드를 실행해야 할 때, 추가적인 시간, 메모리, 자원

#### 3. 메모리 관리 알고리즘

- First-fit
    - 요청된 크기를 수용할 수 있을 만큼 큰 첫 번째 메모리 블록을 검색
    - 남은 공간이 다른 할당을 수용하기에 충분히 큰 경우 블록을 두 부분으로 나눔

- Best-fit
    - 요청된 크기를 수용할 수 있는 가능한 가장 작은 메모리 블록을 검색
    - 내부 단편화를 최소화하는 것을 목표
    - 전체 사용 가능 목록을 검색해야 하기 때문에 Best-fit보다 느릴 수 있음


- Worst-fit
    - 사용 가능한 가장 큰 메모리 블록을 검색하고 여기에서 요청된 크기를 할당
    - 향후 할당을 위해 큰 여유 블록을 남겨두는 것을 목표
    - 외부 단편화를 증가시킬 수 잇음

- Buddy System
    - 메모리를 2의 거듭제곱 크기 블록으로 나누는 메모리 할당 체계
    - 요청된 크기를 수용할 수 있는 가장 작은 블록이 할당됨.
    - 단편화가 적고 할당/해제가 빠르지만 고정된 블록 크기로 인해 내부 단편화 발생할 수 있다.

*내부 단편화?*   
필요한 양보다 더 큰 메모리가 할당되어서 프로세스에서 사용하는 메모리 공간이 낭비 되는 현상

*외부 단편화?*   
작업보다 많은 공간이 남아 있더라도 실제로 그 작업을 받아 들이지 못하는 경우   
여유 공간이 여러 조각으로 나뉘는 현상
<br>

---

<br>

### 2.4 페이징 및 세분화
메모리 리소스를 잘 활용하고 프로세스를 격리하기 위해 메모리를 더 작은 단위로 나누는 것


#### 1. 페이징/Paging
**페이징이란?** 메모리를 페이지라고 하는 고정 크기 블록으로 나누는 메모리 관리 기술   
각 프로세스에는 논리적(가상) 주소 공간을 물리적 메모리에 매핑하는 페이지 테이블(Page Table)이 있다.

- 페이지 테이블
    - 운영 체제에서 논리적 메모리와 물리적 메모리 간의 매핑을 관리하는데 사용하는 데이터 구조
    - 물리적 주소, 액세스 권한 및 상태와 같은 **페이지** 정보가 포함됨
    - 메모리에 저장되며 주소 변환을 수행하기 위해 메모리 관리 장치(MMU)에 의해 엑세스

- 주소 변환
    - 프로세스가 메모리에 액세스 하면 MMU는 프로세스의 페이지 테이블을 사용하여 논리적 주소를 물리적 주소로 변환함
        1. 논리 주소를 페이지 번호와 페이지 내의 오프셋으로 나눔.
        2. 페이지 번호를 사용하여 페이지 테이블에서 해당 물리적 페이지 번호를 찾음.
        3. 물리적 페이지 번호를 오프셋과 결합하여 물리적 주소를 생성.

- 장점
    - 메모리 보호
        - 각 프로세스에는 고유한 페이지 테이블이 있어 다른 프로세스로 부터 메로리를 격리, 우발적 or 악의적 간섭 방지
    - 효율적인 메모리 활용
        - 페이징을 통해 프로세스 간 메모리 공유가 향상되어 낭비되는 메모리 양이 줄어듬.
    - 간소화된 메모리 관리
        - 페이징은 균일한 주소 공간을 제공하여 메모리를 보다 쉽게 관리

- 단점
    - 오버헤드
        - 페이지 테이블을 유지하고 주소 변환을 수행해야 하는 필요성과 같은 추가 오버헤드 도입
    - 내부 조각화
        - 페이지 크기가 고정되어 있기 때문에 프로세스의 마지막 페이지가 완전히 활용되지 않아 메모리 낭비 발생

#### 2. 세그먼테이션/Segmentation
**세그먼테이션이란?** 메모리를 코드, 데이터 및 스택과 같은 논리적 분할을 기반으로 가변 크기 세그먼트로 분할하는 메모리 관리 기술   
각 프로세스에는 논리적 주소 공간을 물리적 메모리에 매핑하는 세그먼트 테이블이 존재

- 세그먼트 테이블
    - 운영 체제에서 논리적 메모리와 물리적 메모리 간의 매핑을 관리할때 사용하는 데이터 구조
    - 물리적 주소, 액세스 권한 및 상태와 같은 **세그먼트** 정보가 포함됨
    - 메모리에 저장되고 주소 변환을 수행하기 위해 MMU에 의해 액세스

- 주소 변환
    - 프로세스가 메모리에 액세스하면 MMU는 프로세스의 세그먼트 테이블을 사용하여 논리적 주소를 물리적 주소로 변환   
        1. 논리 주소를 세그먼트 번호와 세그먼트 내 오프셋으로 나눔
        2. 세그먼트 번호를 사용하여 세그먼트 테이블에서 해당 물리적 세그먼트 기본 주소 및 크기를 찾음
        3. 오프셋이 세그먼트 크기 내에 있는지 확인하고 기본 주소와 결합하여 물리적 주소 생성

- 장점
    - 유연한 메모리 관리
        - 분할을 통해 가변 크기 단위로 메모리를 할당할 수 있으므로 내무 조각화를 줄이고 메모리 활용도를 높인다.
    - 향상된 메모리 보호
        - 정밀한 메모리 보호를 허용하는 세분화된 액세스 제어를 제공
    - 논리적 조직
        - 논리적 분할을 기반으로 메모리를 구성하고 개발자가 더 쉽게 이해하고 관리할 수 있다.

- 단점
    - 오버헤드
        - 분할은 세그먼트 테이블을 유지하고 주소 변환을 수행해야 하는 필요성과 같은 추가 오버헤드를 도입
    - 외부 조각화
        - 크기가 가변적이기 때문에 외부 조각화로 이어질 수 있음.
        - 사용 가능한 메모리는 주소 공간 전체에 흩어져 효과적으로 사용할 수 없다.

<br>

---

<br>

### 2.5 가상메모리
> 물리적으로 사용 가능한 것보다 큰 메모리 공간을 제공하기 위해 사용되는 메모리 관리 기술

가상 메모리는 프로세스가 사용하는 논리적 주소 공간과 하드웨어에서 제공하는 물리적 주소 공간을 분리한다는 아이디어를 기반으로 한다.

#### 가상메모리 구현
하드웨어 및 소프트웨어 구성 요소를 조합을 사용하여 구현

1. 메모리 관리 장치(Memory Management Unit/MMU)
    - 가상 주소를 물리적 주소로 변환하는 하드웨어 구성 요소
    - 페이지 테이블 및 세그먼트 테이블을 사용하여 변환
    - 프로세서의 일부 or 별도의 IC로 구현됨

2. 페이지 테이블
    - 가상, 물리적 메모리 간의 매핑을 관리하는 데 사용하는 데이터 구조
    - 각 프로세스에는 메모리에 저장되고 주소 변환 중에 MMU가 액세스하는 자체 페이지 테이블이 존재

3. 스와핑
    - 물리적 메모리와 보조 메모리 간에 데이터를 이동하여 다른 프로세스를 위해 메모리를 확보하는 프로세스
    - 프로세스가 현재 메모리에 없는 페이지에 액세스 해야 하는 경우 OS는 덜 사용되는 페이지를 교체
4. 캐싱
    - 데이터에 액세스하는데 필요한 시간을 줄이기 위해 자주 액세스하는 데이터를 고속 메모리 영역에 저장하는 프로세스
    - 주소 변환 및 데이터 액세스 시간을 줄이기 위해 최근에 액세스한 페이지를 더 빠른 메모리 영역에 저장하는데 사용

#### 장점
- 메모리 보호
    - 프로세스마다 고유한 가상 주소 공간이 있어 메모리를 다른 프로세스와 간섭 방지
- 효율적인 메모리 사용
    - 프로세스 간 더 나은 메모리 공유가 가능하여 낭비되는 메모리를 줄일 수 있음
- 간소화 된 메모리 관리
    - 균일한 주소 공간을 제공하므로 메모리 관리가 더 쉬워진다.

#### 단점
- 성능 오버헤드
    - 페이지 테이블을 유지 관리, 주소 변환 등 추가적인 오버헤드 발생
    - 오버헤드는 리소스가 제한된 시스템에서 성능에 부정적 영향을 미칠 수 있다.

- 스와핑 대기 시간
    - 메모리와 보조 저장소 간에 데이터를 스왑하면 상당한 지연 시간이 발생할 수 있다.

#### 최적화 기술
- 페이징 알고리즘
- 캐시 관리
- 페이지 사이즈
- 프리패칭
- 로드 밸런싱

<br>

---

<br>

### 2.5 페이지 교체 알고리즘

- FIFO(First-In First-Out/선입선출)   
메모리에서 가장 오래된 페이지(먼저 로드된 페이지)를 교체하는 알고리즘
- 장점
    - 단순성
        - 이해하고 구현하기 쉽다.
        - 간단한 메모리 관리 시스템
    - 낮은 오버헤드
        - 복잡한 데이터 구조나 계산이 필요하지 않아 오버헤드 최소화
- 단점
    - 성능 저하
        - 메모리에서 가장 오래된 페이지에 자주 액세스 하는 경우 높은 오류율 초래

- LRU(Least Recently Used)   
가장 오랫동안 참조되지 않은 페이지를 교체하는 알고리즘

- 장점
    - 성능
        - 최근 액세스 기록을 고려하여 페이지 사용량을 나타내는 좋은 지표
    - 적응성
        - 프로세스의 액세스 패턴 변화에 적응할 수 있으므로 다양한 워크로드에 적합
- 단점
    - 구현 복잡성
        - FIFO보다 복잡한 데이터 구조와 알고리즘을 필요
    - 더 높은 오버헤드
        - 정렬된 페이지 목록을 유지하기 위한 오버헤드가 필요

- LFU(Least Frequently Used)
참조횟수가 가장 적은 페이지를 교체하는 알고리즘

- OPT(Optimal)
앞으로 가장 오랫동안 사용하지 않을 페이지를 교체하는 알고리즘
- 장점
    - 최고의 성능
        - 페이지 오류율이 가장 낮기 때문에 최적의 페이지 교체 알고리즘이다.
- 단점
    - 비실용성
        - 향후 페이지 액세스에 대한 정보가 필요
        - 실제 시스템에서는 구현이 불가능